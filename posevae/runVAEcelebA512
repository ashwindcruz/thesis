#!/bin/bash

# Increasing number of samples in each for loop

#

layers=(2 3 4)
latent=(128 256 512)

#for i in `seq 1 1`;
#do
for i in  "${layers[@]}"
do
for j in "${latent[@]}"
do 	
./train.py -g 0 -o 'hidden_512_layers_'$i'_latent_'$j --model-type vae --vae-samples 1 --ntrans 1 --nlatent $j --nhidden 512 --nlayers $i\
 -b 4096 --batch-limit 1000 -t 1000000 --time-print 600 --epoch-sample 100 --log-interval 5 --data celebA_scaled\
 --init-temp 0 --temp-epoch 1 --init-learn 1e-3 --learn-decay 0 --weight-decay 0 --init-model none 
done
done
